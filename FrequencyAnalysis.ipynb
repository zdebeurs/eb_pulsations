{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Must have matplotlib==3.1.3, otherwise Python won't show the last plot (it'll give an error caused by Matplotlib's latest release)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries and Configuration Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import exoplanet as xo\n",
    "from astropy.timeseries import LombScargle\n",
    "from scipy import interpolate, signal, fft\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import lightkurve as lk\n",
    "from astropy.units import cds\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "\n",
    "rcParams.update({\n",
    "    \"figure.dpi\": 200,\n",
    "    \"savefig.dpi\": 300,\n",
    "    \"axes.linewidth\": 2,\n",
    "    \"lines.linewidth\": 2, \n",
    "    \"figure.figsize\": (16,6), \n",
    "    \"text.usetex\": False, \n",
    "    \"axes.titlesize\": 30,\n",
    "    \"axes.labelsize\": 25, ## fontsize of the x any y labels\n",
    "    \"xtick.labelsize\": 20,\n",
    "    \"ytick.labelsize\": 20\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kepler_tref = 2454833\n",
    "lit_period = 2.18909730\n",
    "KIC = 4544587\n",
    "lit_t0 = 121.14 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File KIC4544587/0_43978/tfreq_analysis/lc_original.txt does not exist: 'KIC4544587/0_43978/tfreq_analysis/lc_original.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-fceedc68a9cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msegment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"0_43978\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"KIC%s/%s/tfreq_analysis/lc_original.txt\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKIC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Time\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Flux\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Time\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Flux\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mbadenas/opt/anaconda3/envs/osc37_mkl/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mbadenas/opt/anaconda3/envs/osc37_mkl/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mbadenas/opt/anaconda3/envs/osc37_mkl/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mbadenas/opt/anaconda3/envs/osc37_mkl/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mbadenas/opt/anaconda3/envs/osc37_mkl/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File KIC4544587/0_43978/tfreq_analysis/lc_original.txt does not exist: 'KIC4544587/0_43978/tfreq_analysis/lc_original.txt'"
     ]
    }
   ],
   "source": [
    "segment = \"0_43978\"\n",
    "lc = pd.read_csv(\"KIC%s/%s/tfreq_analysis/lc_original.txt\" %(KIC, segment), sep=\" \", header=1, names=[\"Time\", \"Flux\"])\n",
    "x, y = lc[\"Time\"], lc[\"Flux\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt(path_file, sep = \" \", header = None, names = None):\n",
    "    df =  pd.read_csv(path_file, sep=\" \", header = header, names = names)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osc_data = pd.read_csv(\"KIC%s/%s/tfreq_analysis/osc_results.csv\" %(KIC, segment), header=0, sep=\",\") \n",
    "osc_model = read_txt(\"KIC%s/%s/tfreq_analysis/osc_model.txt\" %(KIC, segment), header = 1, names=[\"Time\", \"Flux\"]);\n",
    "spectrogram_lc = read_txt(\"KIC%s/%s/tfreq_analysis/osc_and_noise_models.txt\" %(KIC, segment), header=1, names=[\"Time\", \"Flux\"])\n",
    "noise_model = read_txt(\"KIC%s/%s/tfreq_analysis/noise_model.txt\" %(KIC, segment), header=1, names=[\"Time\", \"Flux\"])\n",
    "time, flux = spectrogram_lc[\"Time\"].values, spectrogram_lc[\"Flux\"].values\n",
    "time_osc, flux_osc = osc_model[\"Time\"].values, osc_model[\"Flux\"].values\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(16,6))\n",
    "ax.scatter(time, flux, marker=\".\", s=1)\n",
    "ax.set_title(\"Observed Flux - (Phase Curve Model + Eclipse Model)\", y=1.02, fontsize=25)\n",
    "ax.set_xlabel(\"Time - %i [BKJD days]\"%kepler_tref, fontsize=20)\n",
    "ax.set_ylabel(\"Raw Flux (ppt)\", fontsize=20);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if the Data is Evenly Sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uneven_to_evenly_sampled_data(t, f, threshold):\n",
    "    t = np.sort(t)\n",
    "    dt_points = (t[1:] - t[:-1])\n",
    "    outliers, outliers_idx = dt_points[dt_points > threshold], np.where(dt_points > threshold)[0]\n",
    "    dt_median = np.median(dt_points)\n",
    "    npoints_nodata = outliers/dt_median\n",
    "\n",
    "    # Let's plot the outliers\n",
    "    fig, ax = plt.subplots(1,1, figsize=(16,6))\n",
    "    ax.scatter(t[:-1], dt_points, marker=\"o\", s=1, c=\"lightgrey\")\n",
    "    ax.scatter(t[:-1][outliers_idx], outliers, marker=\"o\", c=\"crimson\", s=20, label=\"Outliers\")\n",
    "    ax.legend(fontsize=18)\n",
    "    ax.set_title(\"Time between Observations\")\n",
    "    ax.set_xlabel(\"Time - %i [BKJD days]\"%kepler_tref, fontsize=20)\n",
    "    ax.set_ylabel(\"$\\Delta t$ [d]\", fontsize=20);\n",
    "    \n",
    "    #Let's fill the gaps\n",
    "    fake_flux_function = interp1d(t, f)\n",
    "    new_t = np.array(np.copy(t))\n",
    "    new_f = np.array(np.copy(f))\n",
    "    print(\"Original Length of Time Array = %i\" %len(t))\n",
    "\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    ax.scatter(t, f, marker=\"o\", s=2, c=\"lightsteelblue\", label=\"Original Flux Points\")\n",
    "    for i,idx in enumerate(outliers_idx):\n",
    "        nfake_points = round(npoints_nodata[i])-1\n",
    "        t_init = t[idx]\n",
    "        t_end = t[idx+1]\n",
    "        x_fake_flux =  np.linspace(t_init, t_end, num = nfake_points+2)[1:-1]\n",
    "        y_fake_flux = fake_flux_function(x_fake_flux)\n",
    "        ax.scatter(x_fake_flux, y_fake_flux, marker=\"o\", color=\"red\")\n",
    "        new_t = np.append(new_t, x_fake_flux)\n",
    "        new_f = np.append(new_f, y_fake_flux)\n",
    "\n",
    "    ax.scatter([], [], c=\"red\", label=\"Fake Flux Points\")\n",
    "    ax.set_xlabel(\"Time - %i [BKJD days]\"%kepler_tref)\n",
    "    ax.set_ylabel(\"Raw Flux (ppt)\")\n",
    "    ax.legend(fontsize=18)\n",
    "        \n",
    "    print(\"Final Length of Time Array = %i\" %len(new_t))\n",
    "    print(\"Added %i points.\" %(len(new_t)-len(t)))\n",
    "\n",
    "    \n",
    "    #Let's plot dt again to confirm that we've added fake flux points correctly.\n",
    "    sidx = np.argsort(new_t)\n",
    "    new_t = new_t[sidx]\n",
    "    new_f = new_f[sidx]\n",
    "    \n",
    "    dt_points = (new_t[1:] - new_t[:-1])\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    ax.scatter(new_t[:-1], dt_points, s=15, c=\"grey\")\n",
    "    ax.set_title(\"Time between Observations\")\n",
    "    ax.set_xlabel(\"Time - %i [BKJD days]\"%kepler_tref)\n",
    "    ax.set_ylabel(\"$\\Delta t$ [d]\");\n",
    "    \n",
    "    print(\"Range of time gaps = {:>.3e} days ({:>.3e} times median spacing)\".format((np.max(dt_points) - np.min(dt_points)), (np.max(dt_points) - np.min(dt_points))/np.median(dt_points)))\n",
    "\n",
    "    plt.pause(0.01)\n",
    "    plt.close(\"all\")\n",
    "    \n",
    "    return outliers, outliers_idx, new_t, new_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outlier_threshold = 0.001\n",
    "outliers, outliers_idx, new_time, new_flux = uneven_to_evenly_sampled_data(time, flux, outlier_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "old_time = np.copy(time)\n",
    "old_flux = np.copy(flux)\n",
    "\n",
    "time = np.copy(new_time)\n",
    "flux = np.copy(new_flux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Signal Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_signal_properties(signal, print_res = False):\n",
    "    num_samples = len(flux) #number of samples\n",
    "    sampling_inteval = np.median(np.diff(time)) #sampling interval (or \"rate\"). Time span between consecutive samples [d]\n",
    "    sampling_frequency = 1.0/sampling_inteval # Sampling frequency [1/d] \n",
    "    nyquist_frequency = sampling_frequency/2.0\n",
    "    total_duration = (num_samples - 1) / sampling_frequency #duration of the signal\n",
    "\n",
    "    if print_res: \n",
    "        print(\"Nº of samples = %i\" %num_samples)\n",
    "        print(\"Sampling Interval = %0.08f [d]\" %sampling_inteval)\n",
    "        print(\"Total Duration of Signal = %0.02f [d]\" %total_duration)\n",
    "        print(\"Sampling frequency = %0.02f [d^-1]\" %sampling_frequency)\n",
    "        print(\"Nyquist frequency = %0.02f [d^-1]\" %nyquist_frequency)\n",
    "\n",
    "    return num_samples, sampling_inteval, sampling_frequency, nyquist_frequency, total_duration\n",
    "\n",
    "Nt, dt, fs, f_nyquist, time_span = get_signal_properties(flux, print_res = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Grid of Frequencies and Run LS Periodogram\n",
    "\n",
    "We use a LS periodogram because our data is unevenly sampled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def ls_estimator(t, f, frequencies, filter_period=None, npeaks=15, normalization=\"psd\"):\n",
    "    #Function based on \"exoplanet\"'s' LS estimator code but adjusted for a variable frequency grid\n",
    "    #(https://github.com/exoplanet-dev/exoplanet/blob/main/src/exoplanet/estimators.py)\n",
    "    \n",
    "    # Estimate the power spectrum\n",
    "    periods = 1. / frequencies\n",
    "    model = LombScargle(t, f)\n",
    "    powers = model.power(frequencies, method=\"fast\", normalization=normalization)\n",
    "    powers /= len(t)\n",
    "    power_est = np.array(powers)\n",
    "    \n",
    "    # Identify Peaks\n",
    "    peaks = xo.find_peaks(frequencies, power_est, max_peaks=npeaks)\n",
    "\n",
    "    return dict(periodogram=(frequencies, power_est), peaks=peaks, ls=model)\n",
    "    \n",
    "orbital_frequency = 1/lit_period\n",
    "minfr = 5*orbital_frequency #[d^-1] or 1/(total_duration) #5*orbital freq is about 10 hours\n",
    "maxfr = 200 #[d^-1] #200 d^-1 is about 7 min\n",
    "N_samples_per_peak = 10 #shouldn't be less than 5. 10 often used as a conservative measure to have good spectral resol'n (p. 36 vanderplas)\n",
    "df = 1/(time_span*N_samples_per_peak) #p. 36 vanderplas\n",
    "grid_resolution = (maxfr-minfr)/df+1\n",
    "freq_grid = np.linspace(minfr, maxfr, int(grid_resolution))\n",
    "\n",
    "ls_spec = ls_estimator(time, flux, freq_grid, normalization=\"psd\")\n",
    "ls_spec_old = ls_estimator(old_time, old_flux, freq_grid, normalization=\"psd\")\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(14,6.5))\n",
    "ax.plot(ls_spec_old[\"periodogram\"][0], ls_spec_old[\"periodogram\"][1], label=\"Original LC\",c=\"lightsteelblue\")\n",
    "#ax.plot(ls_spec[\"periodogram\"][0], ls_spec[\"periodogram\"][1], ms=0.5, alpha=0.5, c=\"orange\", label = \"LC with Injected Fake Flux points\")\n",
    "ax.set_xlabel(r\"Frequency [$d^{-1}$]\", size=20)\n",
    "ax.set_ylabel(\"Power\")\n",
    "ax.set_title(\"LS Periodogram\")\n",
    "ax.set(xlim=(0, 1.2*max(osc_data.freq)))\n",
    "ax.text(0.1,0.6, \"Low Frequency g-mode regime\", fontsize=15, transform=ax.transAxes, bbox=dict(facecolor='red', alpha=0.4));\n",
    "ax.text(0.62,0.6, \"High Frequency p-mode regime\", fontsize=15, transform=ax.transAxes, bbox=dict(facecolor='green', alpha=0.4));\n",
    "#ax.legend(fontsize=15)\n",
    "\n",
    "#ax.set(xlim=(min(freq_grid),5));\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"KIC%s/frequency_analysis/lsperiodogram.png\"%KIC, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the data were evenly sampled, the LS periodogram with a \"PSD\" normalization would be equivalent to the Fourier Transform (provided no uncertainties are given). As the cells below show, the results of our LS Periodogram are not quite the same as those from the FFT because the data is not evenly sampled. More information can be found here: https://docs.astropy.org/en/stable/timeseries/lombscargle.html#lomb-scargle-normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.units as u\n",
    "def fourier_periodogram(t, y):\n",
    "    N = len(t)\n",
    "    frequency = np.fft.fftfreq(N, t[1] - t[0])\n",
    "    y_fft = np.fft.fft(y)\n",
    "    positive = (frequency > 0)\n",
    "    return frequency[positive], (1. / N) * abs(y_fft[positive]) ** 2\n",
    "\n",
    "#Our dataset -- Not Evenly Sampeld\n",
    "frequency_fourier, PSD_fourier = fourier_periodogram(time, flux)\n",
    "ls = LombScargle(time, flux) \n",
    "PSD_LS = ls.power(frequency_fourier, normalization=\"psd\")\n",
    "print(u.allclose(PSD_fourier, PSD_LS)) \n",
    "\n",
    "fig, ax = plt.subplots(2,1, figsize=(12,8), sharex=True)\n",
    "fig.subplots_adjust(hspace=0.0)\n",
    "ax[0].plot(frequency_fourier, PSD_fourier, label = \"FFT\")\n",
    "ax[0].plot(frequency_fourier, PSD_LS, alpha = 0.5, label = \"LS\")\n",
    "ax[0].set_title(\"Our Dataset\", fontsize=20)\n",
    "ax[0].legend() \n",
    "ax[0].set_xlabel(r\"Frequency [d$^{-1}$]\")\n",
    "ax[0].set_ylabel(\"Power\", fontsize=20)\n",
    "#ax[0].set_ylim(0,1)\n",
    "\n",
    "ax[1].plot(frequency_fourier, (PSD_fourier-PSD_LS)/PSD_LS)\n",
    "ax[1].set_xlim(0, maxfr)\n",
    "ax[1].set_xlabel(r\"Frequency [d$^{-1}$]\")\n",
    "ax[1].set_ylabel(\"Power\", fontsize=20)\n",
    "#ax[1].set_ylim(0, 4000)\n",
    "#fig.savefig(\"LS_vs_FFT.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc = lk.LightCurve(time = time, flux = flux)\n",
    "pg = lc.to_periodogram(frequency = np.arange(min(freq_grid), f_nyquist, 10E-3), \n",
    "                       method='lombscargle', \n",
    "                       normalization='amplitude')\n",
    "\n",
    "fig,ax = plt.subplots(1,3, figsize=(25, 5))\n",
    "fig.subplots_adjust(wspace=0.25)\n",
    "pg.plot(scale='log', ax=ax[0]);\n",
    "ax[0].set_xlabel(r\"Frequency [d$^{-1}$]\")\n",
    "ax[0].set_ylabel(\"Power\")\n",
    "ax[0].set_xticks([2, 5, 10, 20, 40, 100, 300, int(f_nyquist)])\n",
    "#ax[0].set_xlim([int(min(freq_grid)), int(max(freq_grid))])\n",
    "ax[0].get_xaxis().set_major_formatter(ScalarFormatter())\n",
    "\n",
    "pg.plot(scale='log', ax=ax[1]);\n",
    "ax[1].set_xlabel(r\"Frequency [d$^{-1}$]\")\n",
    "ax[1].set_ylabel(\"Power\")\n",
    "ax[1].set_xticks([2, 3, 4, 6, 10, 20])\n",
    "ax[1].set_xlim([int(min(freq_grid)), 20])\n",
    "ax[1].get_xaxis().set_major_formatter(ScalarFormatter())\n",
    "\n",
    "pg.plot(scale='log', ax=ax[2]);\n",
    "ax[2].set_xlabel(r\"Frequency [d$^{-1}$]\")\n",
    "ax[2].set_ylabel(\"Power\")\n",
    "ax[2].set_xticks([30, 40, 50, 60])\n",
    "ax[2].set_xlim([30, 60])\n",
    "ax[2].get_xaxis().set_major_formatter(ScalarFormatter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_spectrum(freq, flux_fft, freq_lims = None, amp_lims = None):\n",
    "    if freq_lims is None: \n",
    "        freq_min = 0.0\n",
    "        freq_max = np.max(freq)\n",
    "    \n",
    "    else:\n",
    "        freq_min, freq_max = freq_lims\n",
    "        \n",
    "    print(freq_min, freq_max)\n",
    "    fig = plt.figure(figsize = (16, 8))\n",
    "    ax = plt.gca()\n",
    "    ax.plot(freq, np.abs(flux_fft), linewidth = 1, color = 'black')\n",
    "    ax.set_xlabel('Frequency (day$^{-1}$)')\n",
    "    ax.set_ylabel('Amplitude (ppm day)')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlim(freq_lims)\n",
    "    if amp_lims is not None: \n",
    "        ax.set_ylim(amp_lims)\n",
    "    #plt.savefig(dir_fig+\"spectrum_%ito%i.png\"% (freq_min, freq_max), dpi=300)\n",
    "    \n",
    "def plot_raw(time, flux, freq) :\n",
    "    #Plot raw time series and Fourier transform.\n",
    "    \n",
    "    freq_lims, amp_lims, name = (None, [1.0E-1, 1.0E4], 'spectrum_raw_full')        # Whole spectrum.\n",
    "    plot_spectrum(freq, flux_fft, amp_lims = amp_lims, freq_lims = freq_lims)\n",
    "    \n",
    "    freq_lims, amp_lims, name = ([0.0, 15.0], [2.0E0, 3.0E4], 'spectrum_raw_00_15') # First peak.\n",
    "    plot_spectrum(freq, flux_fft, amp_lims = amp_lims, freq_lims = freq_lims)\n",
    "    \n",
    "    freq_lims, amp_lims, name = ([30.0, 55.0], [2.0E0, 3.0E4], 'spectrum_raw_30_55')# Second peak.\n",
    "    plot_spectrum(freq, flux_fft, amp_lims = amp_lims, freq_lims = freq_lims)\n",
    "    \n",
    "    return\n",
    "\n",
    "def get_fft_and_freq(time, flux):\n",
    "\n",
    "    # Calculate the discrete Fourier transform and associated frequencies.\n",
    "    flux_fft = np.fft.rfft(flux)\n",
    "    freq_fft = np.fft.rfftfreq(Nt, d = dt)\n",
    "\n",
    "    return freq_fft, flux_fft\n",
    "\n",
    "freq_fft, flux_fft = get_fft_and_freq(time, flux)\n",
    "plot_raw(time, flux, freq_fft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_filtering_freq_domain_magnitude(freq, flux_fft, flux_fft_filtered, filter_, filter_lower_freq, filter_upper_freq):\n",
    "    #Source: Harry's code\n",
    "    \n",
    "    fig, ax_arr = plt.subplots(2, 1, figsize = (14, 10), gridspec_kw = {'height_ratios': [1, 3]}, sharex = True)\n",
    "    ax = ax_arr[0] \n",
    "    \n",
    "    # Plot the magnitude of the filter.\n",
    "    ax.plot(freq, np.abs(filter_), c = 'g', label = 'Filter', zorder = 10)\n",
    "    ax.legend(loc = 'upper right')\n",
    "\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax = ax_arr[1]\n",
    "\n",
    "    # Plot the flux.\n",
    "    flux_kwargs = {'alpha' : 0.7, 'linewidth' : 1}\n",
    "    abs_flux_fft = np.abs(flux_fft)\n",
    "    i_freq_allowed = np.where(freq > filter_lower_freq)[0]\n",
    "    max_abs_flux_fft = np.max(abs_flux_fft[i_freq_allowed])\n",
    "    flux_fft_normalised = flux_fft/max_abs_flux_fft\n",
    "    #ax.plot(freq, np.abs(flux_fft_normalised), label = 'Flux before filtering', **flux_kwargs) \n",
    "    ax.plot(freq, np.abs(flux_fft), label = 'Flux before filtering', **flux_kwargs) \n",
    "\n",
    "    # Plot the filtered flux.\n",
    "    abs_flux_fft_filtered = np.abs(flux_fft_filtered)\n",
    "    max_abs_flux_fft_filtered = np.max(abs_flux_fft_filtered)\n",
    "    flux_fft_filtered_normalised = flux_fft_filtered/max_abs_flux_fft_filtered\n",
    "    #ax.plot(freq, np.abs(flux_fft_filtered_normalised), label = 'Flux after filtering', **flux_kwargs)\n",
    "    ax.plot(freq, np.abs(flux_fft_filtered), label = 'Flux after filtering', **flux_kwargs)\n",
    "\n",
    "    ax.set_xlabel('Frequency (cycles per day)')\n",
    "    ax.set_ylabel('Spectral amplitude (ppm day)')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlim([freq[0], freq[-1]])\n",
    "    \n",
    "    amp_lims = [1E-3, 2.0E4]\n",
    "    ax.set_ylim(amp_lims)\n",
    "    ax.set_xlim([0.0, 15.0])\n",
    "    ax.legend()\n",
    "\n",
    "    # Plot the cutoff frequency.\n",
    "    for ax in ax_arr:\n",
    "        for freq_ in [filter_lower_freq, filter_upper_freq]:\n",
    "            ax.axvline(freq_, color = 'k', zorder = 9, alpha = 0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    #path_fig = os.path.join(dir_fig, 'filtering_freq.png')\n",
    "    #print('Saving to {:}'.format(path_fig))\n",
    "    #plt.savefig(path_fig, dpi = 300)\n",
    "    return\n",
    "\n",
    "def plot_filtering_time_domain(time, flux, time_downsampled, flux_filtered_downsampled, raw_only = False, d_t = 1.0):\n",
    "    time_span = time[-1] - time[0]\n",
    "    abs_flux = np.abs(flux)\n",
    "    flux_span = np.max(abs_flux)- np.min(abs_flux) \n",
    "    offset = 0.8*flux_span\n",
    "\n",
    "    n_traces = np.ceil(time_span/d_t)\n",
    "    n_traces_int = int(n_traces)\n",
    "\n",
    "    #n_subplots = 3\n",
    "    n_traces = 3 \n",
    "    n_traces_float = float(n_traces)\n",
    "    \n",
    "    #n_subplots_float = float(n_subplots)\n",
    "    #fig, ax_list = plt.subplots(n_subplots, 1, figsize = (11.0, 8.5))\n",
    "    fig = plt.figure(figsize = (14, 10))\n",
    "    ax = plt.gca()\n",
    "    flux_kwargs = {'alpha' : 0.7, 'linewidth' : 1}\n",
    "\n",
    "    #label_flux = 'Raw data'\n",
    "    label_flux = 'After de-trending'\n",
    "    label_flux2 = 'After filtering\\nand downsampling'\n",
    "    \n",
    "    shift = 0\n",
    "    for i in range(n_traces_int):\n",
    "        t0 = time[0] + (i*d_t)\n",
    "        t1 = time[0] + ((i + 1)*d_t)\n",
    "\n",
    "        j = ((time >= t0) & (time <= t1))\n",
    "        k = ((time_downsampled >= t0) & (time_downsampled <= t1))\n",
    "\n",
    "        i_offset = -i*offset\n",
    "\n",
    "        #flux_mean = np.mean(flux[j])\n",
    "        if i == 0:\n",
    "            label_flux = label_flux\n",
    "            label_flux2 = label_flux2\n",
    "        else:\n",
    "            label_flux = None\n",
    "            label_flux2 = None\n",
    "\n",
    "        ax.plot(time[j] - t0, flux[j] + i_offset + shift, c = 'dodgerblue', label = label_flux, **flux_kwargs)\n",
    "        \n",
    "        if not raw_only:\n",
    "            ax.plot(time_downsampled[k] - t0, flux_filtered_downsampled[k] + i_offset + shift, c= 'k', label = label_flux2, **flux_kwargs)\n",
    "\n",
    "\n",
    "    ax.legend(loc = 'lower right', fontsize=20)\n",
    "    ax.set_xlabel('Time (days)')\n",
    "    #ax.set_ylabel('Flux (ppm)')\n",
    "    ax.set_xlim([0.0, d_t])\n",
    "    ax.set_ylim([-(n_traces_int + 0.5)*offset - 3.5, 2.0])\n",
    "    \n",
    "    for axis in ['right', 'left', 'top']:\n",
    "        ax.spines[axis].set_visible(False)\n",
    "\n",
    "    ax.set_yticks([])\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if raw_only:\n",
    "        name_fig = 'flux_gather_raw'\n",
    "\n",
    "    else:\n",
    "        name_fig = 'flux_gather_filtered'\n",
    "        \n",
    "    #path_fig = os.path.join(dir_fig, '{:}.png'.format(name_fig))\n",
    "    #print('Saving to {:}'.format(path_fig))\n",
    "    #plt.savefig(path_fig, dpi = 300)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def filter_flux(time, flux, freq):\n",
    "    # Create a fourth-order zero-phase Butterworth filter.\n",
    "    # A filter with no phase shift is created by applying the filter\n",
    "    # forward and backwards, which doubles the original order of the filter.\n",
    "    \n",
    "    filter_half_order = 2 \n",
    "    filter_lower_freq =  1.0 # Lower cut-off frequency, cycles per day.\n",
    "    filter_upper_freq = maxfr #140.0 # Upper cut-off frequency, cycles per day\n",
    "    \n",
    "    # Filter cut-off frequencies in radians per day.\n",
    "    filter_angular_freqs = 2.0*np.pi*np.array([filter_lower_freq, filter_upper_freq])\n",
    "    \n",
    "    # Get the filter coefficients.\n",
    "    filter_numerator, filter_denominator = signal.butter(filter_half_order, filter_angular_freqs, 'bandpass', analog = True)\n",
    "\n",
    "    # Evaluate the filter at the frequencies of the FFT.\n",
    "    _, filter_ = signal.freqs(filter_numerator, filter_denominator, worN = 2.0*np.pi*freq)\n",
    "    \n",
    "    # Square the filter to get the effect of applying the filter backwards as well.\n",
    "    filter_ = np.abs(filter_)**2.0\n",
    "\n",
    "    flux_fft_filtered = filter_*flux_fft # Apply the filter to the FFT.\n",
    "    \n",
    "    # Reconstruct the filtered signal with inverse FFT.\n",
    "    flux_filtered = np.fft.irfft(flux_fft_filtered, len(flux))\n",
    "    \n",
    "    # Down-sample the filtered signal.\n",
    "    # freq_sampling:  Sampling frequency (cycles per day).\n",
    "    # freq_sampling_downsampled_appx\n",
    "    #   Approximate sampling frequency after downsampling (samples per day).\n",
    "    #   This is chosen to be twice the upper frequency of the bandpass filter,\n",
    "    #   so that the frequency content within the filter limits is adequately\n",
    "    #   sampled.\n",
    "    # sampling_interval_downsampled_appx : Approximate sampling interval after downsampling (days).\n",
    "    # n_samples_downsampled : Number of samples in the time domain after downsampling.\n",
    "    # sampling_interval_downsampled_appx : Sampling interval after downsampling (days).\n",
    "    # time_downsampled : Times of the sample points (days) after downsampling.\n",
    "    # n_samples_downsampled: Number of points (in the time domain) after down-sampling.\n",
    "   \n",
    "    freq_sampling_downsampled_appx = 2.0*filter_upper_freq \n",
    "    sampling_interval_downsampled_appx = 1.0/freq_sampling_downsampled_appx\n",
    "    n_samples_downsampled = int(np.round(time_span/sampling_interval_downsampled_appx)) + 1\n",
    "    time_downsampled = np.linspace(time[0], time[-1], num = n_samples_downsampled)\n",
    "    sampling_interval_downsampled = time_span/(n_samples_downsampled - 1)\n",
    "    freq_downsampled = 1.0/sampling_interval_downsampled\n",
    "    flux_filtered_downsampled = np.interp(time_downsampled, time, flux_filtered)\n",
    "    \n",
    "    # Print sampling info.\n",
    "    print('Original sample frequency:\\t{:>10.2f} samples per day'.format(fs))\n",
    "    print('Final sample frequency:\\t\\t{:>10.2f} samples per day'.format(freq_downsampled))\n",
    "\n",
    "    # Save the down-sampled signal.\n",
    "    fig, ax = plt.subplots(1,1, figsize=(14,6))\n",
    "    ax.scatter(time, flux, s=5, label=\"Original Signal\")\n",
    "    ax.scatter(time_downsampled,flux_filtered_downsampled, s=5, label=\"Downsampled Signal\")\n",
    "    ax.legend(fontsize=20)\n",
    "    ax.set_xlabel('Time (days)')\n",
    "    ax.set_ylabel('Raw Flux (ppm)')\n",
    "    #plt.tight_layout()\n",
    "    #plt.savefig(dir_fig+\"raw_vs_downsampled_signal.png\")\n",
    "    \n",
    "    #array_out = np.array([time_downsampled, flux_filtered_downsampled])\n",
    "    #path_out = os.path.join(dir_fig, 'flux_filtered.txt') \n",
    "    #print('Saving to {:}'.format(path_out))\n",
    "    #np.save(path_out, array_out)\n",
    "    \n",
    "    # Also create a high--pass-only (i.e de-trending) version of the filter (for plotting only).\n",
    "    filter_highpass_numerator, filter_highpass_denominator = signal.butter( filter_half_order, filter_angular_freqs[0], 'high', analog = True)\n",
    "   \n",
    "    # Evaluate the filter at the frequencies of the FFT.\n",
    "    _, filter_highpass = signal.freqs(filter_highpass_numerator, filter_highpass_denominator, worN = 2.0*np.pi*freq)\n",
    "    \n",
    "    # Square the filter to get the effect of applying the filter backwards # as well.\n",
    "    filter_highpass = np.abs(filter_highpass)**2.0\n",
    "\n",
    "    # Apply the filter to the FFT.\n",
    "    flux_fft_highpassed = filter_highpass*flux_fft\n",
    "\n",
    "    # Reconstruct the filtered signal\n",
    "    flux_highpassed = np.fft.irfft(flux_fft_highpassed, len(flux))\n",
    "\n",
    "    # Plot.\n",
    "    plot_filtering_time_domain(time, flux_highpassed, time_downsampled, flux_filtered_downsampled, raw_only = False, d_t = 1.0)\n",
    "    plot_filtering_freq_domain_magnitude(freq, flux_fft, flux_fft_filtered, filter_, filter_lower_freq, filter_upper_freq)\n",
    "\n",
    "    return time_downsampled, flux_filtered_downsampled, freq_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "time_downfiltered, flux_downfiltered, freq_sampling_downfiltered = filter_flux(time, flux, freq_fft)\n",
    "\n",
    "sampling_interval_downfiltered = 1.0/freq_sampling_downfiltered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_window_function(t, fary):\n",
    "    LSwindow = LombScargle(t, 1.0, fit_mean = False, center_data=False)\n",
    "    Pwindow = LSwindow.power(fary)\n",
    "    return LSwindow, Pwindow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#https://github.com/jakevdp/PracticalLombScargle/blob/master/figures/StructuredWindows.ipynb\n",
    "   \n",
    "# WF for old time array\n",
    "ls_window_old, p_window_old = calculate_window_function(old_time, freq_grid)\n",
    "\n",
    "# WF for new time array\n",
    "ls_window, p_window = calculate_window_function(time, freq_grid)\n",
    "\n",
    "# WF for downfiltered (new) time array\n",
    "ls_window_downfiltered, p_window_downfiltered = calculate_window_function(time_downfiltered, freq_grid)\n",
    "\n",
    "# WF for evenly sampled data \n",
    "x_dt = np.arange(0, time_span, dt)\n",
    "ls_window_dt, p_window_dt = calculate_window_function(x_dt, freq_grid)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(16, 6)) \n",
    "ax.plot(freq_grid, p_window_old, label = \"Raw Original Time\")\n",
    "ax.plot(freq_grid, p_window, c=\"green\", ms=0.3, alpha=0.5, label = \"Time (Gaps filled)\")\n",
    "ax.plot(freq_grid, p_window_dt, c=\"orange\", ms=0.2, alpha=0.5, label = \"Evenly sampled data\")\n",
    "ax.plot(freq_grid, p_window_downfiltered, c=\"purple\", ms=0.1, alpha=0.5, label = \"Downfiltered Time\")\n",
    "ax.set_xlabel(r\"Frequency [$d^{-1}$]\", size=25, labelpad=5)\n",
    "ax.set_ylabel(\"Window Power\", size=25, labelpad=10)\n",
    "ax.legend(loc=\"upper right\", fontsize=20)\n",
    "ax.set_xlim(0,40)\n",
    "ax.set_title(\"Periodogram of Observing Window\", fontsize=30);\n",
    "\n",
    "fig, ax = plt.subplots(2, figsize=(15, 10), sharex=True)\n",
    "axs = [ax[0], ax[1]]\n",
    "fig.subplots_adjust(hspace=0.35)\n",
    "ax[0].plot(freq_grid, p_window, c=\"grey\")\n",
    "ax[0].set_ylabel('Window power', fontsize=20)\n",
    "ax[0].set_title('Window Power Spectrum', fontsize=25);\n",
    "\n",
    "ax[1].plot(ls_spec[\"periodogram\"][0], ls_spec[\"periodogram\"][1], \"-k\")\n",
    "ax[1].set_title('Light Curve Power Spectrum', fontsize=25);\n",
    "ax[1].set_ylabel(\"Lomb-Scargle power\", fontsize=20)\n",
    "for a in axs:\n",
    "    a.set_xlim(0,50)\n",
    "    a.set_xlabel('Frequency [d$^{-1}$]', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Spectrogram of Unevenly Sampled Data\n",
    "<a class=\"anchor\" id=\"section_2_3\"></a>\n",
    "\n",
    "The following is an implementation of a spectrogram that can deal with unevently sampled data. It uses the extended Lomb-Scargle periodogram.\n",
    "\n",
    "1. Windows: nice article explaining some of the fundamental ones: https://community.sw.siemens.com/s/article/window-types-hanning-flattop-uniform-tukey-and-exponential Note on windows: Windows are used to \"stretch\" the frequency peaks. With spectrograms, one tries to overlap them so that each measurement is taken into account with the same weight as every other measurement.\n",
    "\n",
    "2. dt2: (a) Too high time resolution (low Δ𝑡2 ) will result in fuzziness along the frequency direction (b) Too low time resolution (high Δ𝑡2 ) will result in the inability to capture frequencies changing too fast over time (c) trade off time resolution will give a well focused spectrogram with able to detect frequencies that change over tim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spectrogram(time, flux):\n",
    "    \n",
    "    #Create Tukey Window \n",
    "    alpha = 0.25      # \"Shape parameter of the Tukey window, representing the fraction of the window inside the cosine tapered region. If zero, the Tukey window is equivalent to a rectangular window. If one, the Tukey window is equivalent to a Hann window.\"\n",
    "    window = (\"tukey\", alpha)\n",
    "    Nwindow = 101  # Nº of sample points to interpolate from the window\n",
    "    N_samples_per_peak = 10 #shouldn't be less than 10\n",
    "    \n",
    "    print(\"* Generating a TUKEY window with...\")\n",
    "    print(\"     alpha = %0.02f\" %alpha)\n",
    "    print(\"     Nº of sample points to interpolate from window  = %i\" %Nwindow)\n",
    "    \n",
    "    # Desired Time Resolution and Overlap\n",
    "    dt2 = 0.16 \n",
    "    overlap = alpha/2 #Currently set to 1/8, which is the default spectrogram value in python. \n",
    "    print(\"\\n* Generating Spectrogram with...\")\n",
    "    print(\"     Desired Time Resolution = %0.02f \" % dt2)\n",
    "    print(\"     Desired Overlap = %0.02f\" %overlap)\n",
    "    \n",
    "    #Max. Nº of samples per chunk for a given overlap\n",
    "    Nt_chunk = dt2 / dt / (1 - overlap) # max. nº of samples per segment with an overlap equal to \"overlap\", if dt2 is to be respected\n",
    "    Nt_chunk = max(int(2**np.floor(np.log2(Nt_chunk))), 2) # closer power of two below maximum. note: FFTs work best when N is a power of 2.\n",
    "    print(\"\\n* If Desired Time Resolution and Overlap is to be respected, we have...\")\n",
    "    print(\"     Nº of samples per window = %i\" %Nt_chunk)\n",
    "    \n",
    "    #Time resolution of each window.\n",
    "    effective_dt2 = (Nt_chunk - Nt_chunk//(1/overlap))*dt\n",
    "    print(\"     Time resolution per window = %0.03f [d] (desired %0.03f [d])\" %(effective_dt2, dt2))\n",
    "    \n",
    "    #Duration of each segment\n",
    "    Tseg = dt * (Nt_chunk - 1) # Duration of one chunk (= duration of one window)\n",
    "    print(\"     Duration of one window = %0.03f [d]. This yields an effective frequency resolution of %0.02f [d^-1]\" %(Tseg, 1/Tseg))\n",
    "    \n",
    "    #Create Spectrogram Time Array\n",
    "    #The variable `t2` is the center of each window. It goes from where the 1st time measurement is\n",
    "    #plus T_seg/2 (half a window), to where the last time measurement is minus the region that is overlapped\n",
    "    print(\"\\n* Creating the Spectrogram TIME Array...\")\n",
    "    t2 = np.arange(time[0]+Tseg/2, time[-1]-Tseg/2, Tseg*(1-overlap))\n",
    "    t_seg_start = t2 - Tseg/2\n",
    "    t_seg_end   = t2 + Tseg/2\n",
    "    \n",
    "    #Create Spectrogram Frequency Array\n",
    "    print(\"* Creating the Spectrogram FREQUENCY Array...\")\n",
    "    df2 = 1/(Tseg*N_samples_per_peak) #p.36 vanderplas\n",
    "    grid_resolution_spectrogram = (maxfr-minfr)/df2+1\n",
    "    f2 = np.linspace(minfr, maxfr, int(grid_resolution_spectrogram))\n",
    "    \n",
    "    #Prepare window to be applied to the data\n",
    "    window_data = signal.get_window(window, Nwindow)\n",
    "    window_t = np.arange(0, Nwindow) * Tseg/(Nwindow - 1)\n",
    "    get_window_value = interpolate.interp1d(window_t, window_data)\n",
    "    apply_window = lambda t, x: x*get_window_value(t)\n",
    "    \n",
    "    #Generate the Spectrogram\n",
    "    P = np.zeros((f2.size, t2.size))\n",
    "    print(\"* Generating the Spectrogram...\")\n",
    "    for i in range(t2.size):\n",
    "        t_seg_flag = np.logical_and(time >= t_seg_start[i], time < t_seg_end[i])\n",
    "        ind_seg = np.flatnonzero(t_seg_flag)\n",
    "\n",
    "        if ind_seg.size < 2:  # No data in this segment, skip\n",
    "            P[:,i] = np.nan\n",
    "            continue\n",
    "\n",
    "        t_seg = time[ind_seg] - t_seg_start[i]\n",
    "        y_seg = flux[ind_seg]\n",
    "\n",
    "        # Detrend\n",
    "        y_seg = signal.detrend(y_seg, type=\"linear\")\n",
    "\n",
    "        # Window\n",
    "        y_seg = apply_window(t_seg, y_seg) #Apply the given window to the given array along the given axis.\n",
    "\n",
    "        # Lomb Scargle\n",
    "        ls = LombScargle(t_seg, y_seg, normalization='psd')\n",
    "        p = ls.power(f2)\n",
    "\n",
    "        P[:,i] = p\n",
    "    \n",
    "    print(\"--> Done.\")\n",
    "    return P, t2, f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "P, t2, f2 = create_spectrogram(time_osc, flux_osc)\n",
    "\n",
    "f_min = min(freq_grid)\n",
    "f_max = int(1.2*max(osc_data[\"freq\"]))\n",
    "f_range = f_max-f_min\n",
    "pmin = 0.0\n",
    "color_map =\"magma\" #\"coolwarm\" #\"magma\" #\"coolwarm\" #\"Blues\" #\"RdYlBu_r\" #\"RdYlBu_r\", \"Greysd\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(15,10))\n",
    "s = ax.pcolormesh(t2, f2, 10*np.log10(P), vmin=pmin,  cmap=color_map)# =\"RdYlBu_r\")\n",
    "ax.set_ylabel(r'Frequency [$d^{-1}$]', size=30, labelpad=15)\n",
    "ax.set_xlabel('Time [BKJD]', size=30, labelpad=15)\n",
    "ax.set_ylim(min(freq_grid),f_max)\n",
    "fig.colorbar(s, ax=ax, label = \"Power [dB]\")\n",
    "ax.set_title(r\"Spectrogram with f $>$ %i $d^{-1}$ masked out\" %f_max,  y=1.02);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widths = [5, 1.2] # two columns, with widths ratio 6 to 1\n",
    "heights = [2, 6, 1, .4] # 4 columns\n",
    "\n",
    "#   height of top plot, central plot, space for xlabels of central plot and colorbar below\n",
    "fig, _ = plt.subplots(0, 0, figsize=(20,14))\n",
    "grid = plt.GridSpec(\n",
    "    4,\n",
    "    2,\n",
    "    hspace=0.05,\n",
    "    wspace=0.02,\n",
    "    figure=fig,\n",
    "    width_ratios=widths,\n",
    "    height_ratios=heights,\n",
    ")\n",
    "# Set up main plot: time vs freq and power as color\n",
    "ax = fig.add_subplot(grid[1:-2, :-1])\n",
    "\n",
    "# Set up top plot\n",
    "ax_top = fig.add_subplot(grid[0, :-1])\n",
    "ax_top.scatter(time, flux, c=\"lightsteelblue\", s=1)  \n",
    "ax_top.set_ylabel(\"Downfiltered Flux [ppt]\", size=25)\n",
    "ax_top.set_title(\"Spectrogram Input Data (Observed Flux - (Phase Curve + Eclipse Models)\", size=22, y=1.05);\n",
    "\n",
    "# Set up right plot: freq as y axis hence sharey. NOTE it's inverted wrt the figure above\n",
    "ax_right = fig.add_subplot(grid[1:-2, -1], sharey=ax)\n",
    "ax_right.plot(ls_spec[\"periodogram\"][1], ls_spec[\"periodogram\"][0], c=\"k\") \n",
    "ax_right.set_xlabel(\"Power\", size=25)\n",
    "ax_right.set_ylim(f_min, f_max)\n",
    "ax_right.set_title(\"LS Periodogram\", size=28, y=1.02);\n",
    "\n",
    "# Create axes for colorbar below\n",
    "ax_bottom = fig.add_subplot(grid[-1, :-1])\n",
    "\n",
    "# Personalize axes\n",
    "ax_top.tick_params(labelbottom=False)\n",
    "ax_right.tick_params(labelleft=False)\n",
    "\n",
    "# main plot\n",
    "mesh_power = ax.pcolormesh(t2, f2, 10*np.log10(P), vmin=pmin, cmap=color_map)\n",
    "ax.set_ylabel(r'Frequency [$d^{-1}$]', size=25)\n",
    "ax.set_xlabel(\"Time - %i [BKJD days]\"%kepler_tref, size=25)\n",
    "ax.set_ylim(f_min, f_max)\n",
    "fig.colorbar(mesh_power, cax=ax_bottom, label = \"Power [dB]\", orientation=\"horizontal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Resolution Spectrogram "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose overlap and overlap factor. Notes: \n",
    "* Window length will be given by `n_overlap`*`overlap_factor`.\n",
    "* n_overlap list should have two values, where the second value is half the first value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrogram(d_t, t_corners, f_corners, spectrogram_grid, t_lims = None, f_lims = None, name = None, variable = 'amp', units = 'physical', ft_mesh = None, show_mesh = False):\n",
    "    # Note: Both amplitude and power get multiplied by one power of d_t to give appropriate units and correct limit as d_t -> 0.0.\n",
    "    \n",
    "    amplitude_spectrum      = np.abs(spectrogram_grid)*d_t\n",
    "    power_spectrum          = (np.abs(spectrogram_grid)**2.0)*d_t\n",
    "\n",
    "    assert variable in ['amp', 'power']\n",
    "    assert units in ['physical', 'decibels']\n",
    "\n",
    "    if variable == 'amp':\n",
    "        if units == 'physical':\n",
    "            Z = amplitude_spectrum\n",
    "            Z_label = 'Amplitude (ppt day)'\n",
    "            Z_lims = [1.0E-3, 2.0E-1]\n",
    "            \n",
    "        elif units == 'decibels':      \n",
    "            Z0 = 1.0 # Reference amplitude in units of ppt day.\n",
    "            Z = 20.0*np.log10(amplitude_spectrum/Z0)\n",
    "            Z_label = 'Amplitude (20 $\\log A/A_{0}$)'\n",
    "\n",
    "    elif variable == 'power':\n",
    "        if units == 'physical':\n",
    "            Z = np.abs(spectrogram_grid)**2.0\n",
    "            Z_label = 'Power (ppt$^{2}$ day)'\n",
    "            Z_lims = [3.0E-3, 1.0E4]\n",
    "            \n",
    "        elif units == 'decibels':\n",
    "            Z0 = 1.0 # Reference amplitude in units of (ppt^2) day.\n",
    "            Z = 20.0*np.log10(power_spectrum/Z0)\n",
    "            Z_label = 'Power (10 $\\log_{10} P/P_{0})'\n",
    "\n",
    "    #print(np.min(np.log10(Z)), np.max(np.log10(Z)))\n",
    "\n",
    "    # Create the axes.\n",
    "    fig = plt.figure(figsize = (11.0, 8.5))\n",
    "    ax  = plt.gca()\n",
    "    \n",
    "    ## Find the colour-bar limits. Use a logarithmic colour-bar normalisation.\n",
    "    c_norm = colors.LogNorm(vmin = Z_lims[0], vmax = Z_lims[1])\n",
    "\n",
    "    if show_mesh: kwargs = {'edgecolor' : 'k'}\n",
    "    else: kwargs = {}\n",
    "\n",
    "    # Plot the spectrogram.\n",
    "    image = ax.pcolormesh(t_corners, f_corners, Z.T, cmap = 'magma', norm = c_norm, **kwargs)\n",
    "\n",
    "    #if ft_mesh is not None:\n",
    "    #    for tc in ft_mesh[1]: ax.axvline(tc, alpha = 0.5, color = 'k')\n",
    "    #    for fc in ft_mesh[0]: ax.axhline(fc, alpha = 0.5, color = 'k')\n",
    "\n",
    "    # Tidy the axes.\n",
    "    ax.set_xlabel('Time (days)', fontsize = font_size_label)\n",
    "    ax.set_ylabel('Frequency (cycles per day)', fontsize = font_size_label)\n",
    "    #\n",
    "    if f_lims is not None: ax.set_ylim(f_lims)\n",
    "    if t_lims is not None: ax.set_xlim(t_lims)\n",
    "\n",
    "    # Add the colour bar.\n",
    "    divider = make_axes_locatable(ax)\n",
    "    c_ax = divider.append_axes('right', size = '2%', pad = 0.05)\n",
    "    c_bar = fig.colorbar(image, cax = c_ax, orientation = 'vertical') \n",
    "    c_bar.ax.set_ylabel(Z_label, fontsize = font_size_label)\n",
    "\n",
    "    # Tight layout.\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the figure.\n",
    "    if name is not None:\n",
    "        path_fig = os.path.join('plots', '{:}.png'.format(name))\n",
    "        print('Saving to {:}'.format(path_fig))\n",
    "        plt.savefig(path_fig)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_window_function(f_win):\n",
    "    fig = plt.figure(figsize = (12, 6))\n",
    "    ax = plt.gca()\n",
    "    ax.plot(f_win, marker = '.')\n",
    "    ax.set_xlabel('Sample ID', fontsize=25)\n",
    "    ax.set_ylabel('Window function', fontsize=25)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def plot_windows(i0, i1, n_samples):\n",
    "    n_windows = len(i0)\n",
    "    offsets = np.array(list(range(n_windows))) + 1.0\n",
    "\n",
    "    fig = plt.figure(figsize = (12, 6))\n",
    "    ax  = plt.gca()\n",
    "    \n",
    "    print('Window  First   Last')\n",
    "    for j in range(n_windows):\n",
    "        print('{:>5d} {:>5d} {:>5d}'.format(j, i0[j], i1[j]))\n",
    "        i_window = np.array(list(range(i0[j], i1[j])), dtype = np.int)\n",
    "        ax.scatter(i_window, np.zeros(len(i_window)) + offsets[j], s = 1, color = 'r') \n",
    "        \n",
    "    #Each red line is one of the windows. These windows overlap with each other. \n",
    "    #The last window doesn't quite go to the end bc the length of the window is not a perfect multiple of the length of the timeseries\n",
    "\n",
    "    ax.set_xlabel('Sample index')\n",
    "    ax.set_ylabel('Window ID')\n",
    "    ax.axvline(0)\n",
    "    ax.axvline(n_samples - 1)\n",
    "    buff = 0.05*i1[-1]\n",
    "    ax.set_xlim([-buff, n_samples + buff])\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cosine_window(length, edge_length):\n",
    "    #We'll use a cosine window. we could also use a Tukey window\n",
    "    \n",
    "    # Interior part is just ones.\n",
    "    f_win = np.zeros(length) + 1.0\n",
    "    \n",
    "    # Left edge is an increasing cosine taper.\n",
    "    left_edge_pts = (np.pi)*np.linspace(-1.0, 0.0, num = edge_length)\n",
    "    f_win[0 : edge_length] = np.cos(left_edge_pts)\n",
    "\n",
    "    # Right edge is a decreasing cosine taper.\n",
    "    right_edge_pts = (np.pi)*np.linspace(0.0, 1.0, num = edge_length)\n",
    "    f_win[-edge_length : ] = np.cos(right_edge_pts)\n",
    "    \n",
    "    return f_win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrogram(x, d_t, n_samples_per_window, n_overlap, offset = 0, show_helper_plots = True):\n",
    "\n",
    "    # Generate the window function.\n",
    "    window_function = create_cosine_window(n_samples_per_window, n_overlap)\n",
    "\n",
    "    # Plot the window function.\n",
    "    if show_helper_plots: plot_window_function(window_function)\n",
    "\n",
    "    # Calculate sampling frequency (note: assumes uniformly-spaced data).\n",
    "    n_samples = len(x)\n",
    "    time_span = (n_samples - 1)*d_t\n",
    "    sampling_freq = 1.0/d_t\n",
    "\n",
    "    # Calculate the number of windows that fit in the total dataset \n",
    "    shift_per_window = (n_samples_per_window - n_overlap)\n",
    "    n_windows = ((n_samples - n_samples_per_window - offset)//shift_per_window) + 1\n",
    "    \n",
    "    # Note: Excess points at the end are not used. \n",
    "    # These two lines below don't affect the code, it's just for visualization purposes. \n",
    "    n_final = (n_windows - 1)*shift_per_window + n_samples_per_window + offset\n",
    "    n_ignore = n_samples - n_final\n",
    "\n",
    "    # Print some useful information.\n",
    "    window_length = (n_samples_per_window - 1)*d_t\n",
    "    overlap_length = (n_overlap - 1)*d_t\n",
    "    print('Calculating spectrogram.')\n",
    "    print('Total length of time series: {:>.3f} days ({:>5d} samples).'.format(time_span, n_samples))\n",
    "    print('Window length: {:>.3f} days ({:>5d} samples).'.format(window_length, n_samples_per_window))\n",
    "    print('Overlap:       {:>.3f} days ({:>5d} samples).'.format(overlap_length, n_overlap))\n",
    "    print('Number of windows: {:>5d}'.format(n_windows))\n",
    "    print('Samples skipped at beginning: {:>5d}.'.format(offset))\n",
    "    print('Number of samples ignored at end: {:>5d}.'.format(n_ignore))\n",
    "\n",
    "    # Get the start and end index of each window.\n",
    "    i0 = np.array(list(range(n_windows)), dtype = np.int)*shift_per_window #start index\n",
    "    i1 = i0 + n_samples_per_window\n",
    "    #\n",
    "    i0 = i0 + offset\n",
    "    i1 = i1 + offset\n",
    "\n",
    "    # Plot the windows.\n",
    "    if show_helper_plots: plot_windows(i0, i1, n_samples)\n",
    "        \n",
    "    # Get the frequencies.\n",
    "    freq = np.fft.rfftfreq(n_samples_per_window, d_t)\n",
    "    n_freq = len(freq)\n",
    "    \n",
    "    # Get the times at the start, end, and middle of each window.\n",
    "    t_mid = np.zeros(n_windows)\n",
    "    t0 = np.zeros(n_windows)\n",
    "    t1 = np.zeros(n_windows)\n",
    "    for j in range(n_windows):\n",
    "        t0[j] = d_t*i0[j] #start time\n",
    "        t1[j] = t0[j] + window_length #end time\n",
    "        t_mid[j] = (t0[j] + t1[j])/2.0 #midpoint of the time window\n",
    "\n",
    "    \n",
    "    # Initialise the spectrogram array.\n",
    "    spectrogram = np.zeros((n_windows, n_freq), dtype = np.complex)\n",
    "    for j in range(n_windows):    \n",
    "        #print('Calculating spectrogram for window {:>5d} of {:>5d}'.format(j + 1, n_windows))\n",
    "        x_windowed = window_function*(x[i0[j] : i1[j]])\n",
    "        spectrogram[j, :] = np.fft.rfft(x_windowed) #we'll use real data, so that's why we are running rfft\n",
    "\n",
    "    # Find the corners of (each pixel) of the frequency grid. \n",
    "    #this is only necessary for plotting purposes. \n",
    "    #the frequencies are evenly spaced (thanks to linearity of Fourier transform).\n",
    "    freq_corners = np.zeros(n_freq + 1)\n",
    "    freq_corners[1:-1] = freq[0:-1] + 0.5*np.diff(freq)\n",
    "    freq_corners[-1] = freq[-1] + 0.5*(freq[-1] - freq[-2]) #the pixel will be the same size as the previous pixel\n",
    "\n",
    "    # Find the corners of the time grid. \n",
    "    #Since there is a slight overlap between each window, we choose\n",
    "    #the midpoint of the pixel as halfway through the two overlapping \n",
    "    #points of one window and the next. \n",
    "    t_corners = np.zeros(n_windows + 1)\n",
    "    for j in range(1, n_windows):\n",
    "        t_corners[j] = (t1[j - 1] + t0[j])/2.0\n",
    "    \n",
    "    t_corners[0] = t0[0] \n",
    "    t_corners[-1] = t_corners[-2] + (t_corners[-2] - t_corners[-3]) \n",
    "\n",
    "    return t0, t1, t_mid, t_corners, freq, freq_corners, spectrogram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrogram_two_resolutions(x, d_t, n_samples_per_window_list, n_overlap_list, offset_list, merge_frequency, show_helper_plots = True):\n",
    "    # Coarser times: t_corners_A.\n",
    "    # Coarser freqs: f_corners_B.\n",
    "    _, _, _, t_corners_A, _, f_corners_A, x_spectrogram_A = \\\n",
    "        spectrogram(x, d_t, n_samples_per_window_list[0], n_overlap_list[0],\n",
    "                    offset = offset_list[0],\n",
    "                    show_helper_plots = show_helper_plots)\n",
    "    #\n",
    "    _, _, _, t_corners_B, _, f_corners_B, x_spectrogram_B = \\\n",
    "        spectrogram(x, d_t, n_samples_per_window_list[1], n_overlap_list[1],\n",
    "                    offset = offset_list[1],\n",
    "                    show_helper_plots = show_helper_plots)\n",
    "\n",
    "    # We now must move the spectrograms onto a finer grid, so that they can be merged. This involves \n",
    "    # increasing the time resolution of one of the spectrograms (by repeating elements) and increasing\n",
    "    # the spectral resolution of both spectrograms (as their spectral grids will otherwise not match up).\n",
    "\n",
    "    # Double the time resolution of the coarse time spectrogram.\n",
    "    x_spectrogram_A_new = np.repeat(x_spectrogram_A, 2, axis = 0)\n",
    "    \n",
    "    # Fill any gaps at the end of the x-axis with zeros.\n",
    "    n_t_missing = (len(t_corners_B) - x_spectrogram_A_new.shape[0] - 1)\n",
    "    \n",
    "    if n_t_missing > 0:\n",
    "        x_spectrogram_A_new = np.pad(x_spectrogram_A_new, ((0, n_t_missing), (0, 0)))\n",
    "    \n",
    "    # Rename variables.\n",
    "    t_corners_new = t_corners_B #time array for the merged spectrogram.  \n",
    "    x_spectrogram_A_tmp = x_spectrogram_A_new.copy()\n",
    "\n",
    "    # Determine the new master frequency grid.\n",
    "    f_corner_max = f_corners_B[-1]\n",
    "    n_f_corners_new = int(round((f_corner_max/(np.median(np.diff(f_corners_A)))))) + 1\n",
    "    n_f_corners_new = 2*n_f_corners_new - 1\n",
    "    f_corners_new = np.linspace(0.0, f_corner_max, num = n_f_corners_new)\n",
    "\n",
    "    # Initialise re-gridded spectrograms.\n",
    "    n_t_new = x_spectrogram_A_tmp.shape[0]\n",
    "    x_spectrogram_A_new = np.zeros((n_t_new, n_f_corners_new - 1), dtype = np.complex)\n",
    "    x_spectrogram_B_new = np.zeros((n_t_new, n_f_corners_new - 1), dtype = np.complex)\n",
    "\n",
    "    # To resample high-fuency version, each element must be repeated twice (except first element).\n",
    "    # First element is not repeated.\n",
    "    x_spectrogram_A_new[:, 0] = x_spectrogram_A_tmp[:, 0]\n",
    "    \n",
    "    # Repeat the elements.\n",
    "    x_spectrogram_A_new[:, 1:-1] = np.repeat(x_spectrogram_A_tmp[:, 1:], 2, axis = 1)\n",
    "\n",
    "    # To re-sample low-fuency version, each element must be repeated four times (except first element).\n",
    "    # First element is repeated only once.\n",
    "    x_spectrogram_B_new[:, 0] = x_spectrogram_B[:, 0]\n",
    "    x_spectrogram_B_new[:, 1] = x_spectrogram_B[:, 0]\n",
    "\n",
    "    # Repeat the elements.\n",
    "    x_spectrogram_B_new[:, 2:] = np.repeat(x_spectrogram_B[:, 1:], 4, axis = 1)\n",
    "\n",
    "    # Merge the spectrograms.\n",
    "    i_f_switch = np.argmax(f_corners_new > merge_frequency)\n",
    "    x_spectrogram_merged = np.zeros(x_spectrogram_A_new.shape, dtype = np.complex)\n",
    "    x_spectrogram_merged[:, 0 : i_f_switch] = x_spectrogram_A_new[:, 0 : i_f_switch]\n",
    "    x_spectrogram_merged[:, i_f_switch : ] = x_spectrogram_B_new[:, i_f_switch : ]\n",
    "\n",
    "    return  t_corners_A,        f_corners_A,        x_spectrogram_A, \\\n",
    "            t_corners_B,        f_corners_B,        x_spectrogram_B, \\\n",
    "            t_corners_new,      f_corners_new,      x_spectrogram_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 1st spectrogram has a bigger window length. It is used for the lower part of the spectrogram, which is where the shorter frequencies are (they have longer cycles).  the shorter frequencies. The 2nd spectrogram has a shorter window length. In the following arrays, the 1st and 2nd item refer to the 1st and 2nd spectrogram, respectively. We've chosen the window length of one spectrogram to be half of the other one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_factor = 8 #what fraction of the window overlaps with the previous windows (1/8)\n",
    "n_overlap_bigger = 128 #number of samples that overlap with the previous one (128 is quite big) -> the window length will be 8*128, which is 1024\n",
    "n_overlap_list = [n_overlap_bigger, n_overlap_bigger//2] #the 1st and 2nd item is for the 1st and 2nd spectrogram, respectively\n",
    "offset_list = [0, n_overlap_list[1]//2] #the 0 is for the bigger window, and the 2nd item is for the smaller window.  \n",
    "n_samples_per_window_list = [overlap_factor*n_overlap for n_overlap in n_overlap_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the two spectrograms and merge them.\n",
    "show_helper_plots = True\n",
    "merge_frequency = 30.0 # Cycles per day. this is the cut-off at which the transition takes place\n",
    "t_corners_A,        f_corners_A,        flux_spectrogram_A, \\\n",
    "t_corners_B,        f_corners_B,        flux_spectrogram_B, \\\n",
    "t_corners_merged,   f_corners_merged,   flux_spectrogram_merged, \\\n",
    "= spectrogram_two_resolutions(flux, dt, n_samples_per_window_list,\n",
    "                              n_overlap_list, offset_list, merge_frequency,\n",
    "                              show_helper_plots = show_helper_plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the merged and un-merged spectrograms.\n",
    "font_size_label = 25\n",
    "common_args = { 'variable' : 'amp', 'units' : 'physical',\n",
    "               't_lims' : [0.0, np.max(time) - np.min(time)],\n",
    "               'f_lims' : [0.0, 60.0]}\n",
    "\n",
    "name_list = ['spectrogram_{:>05d}'.format(n_samples_per_window) for n_samples_per_window in n_samples_per_window_list]\n",
    "plot_spectrogram(dt, t_corners_A, f_corners_A, flux_spectrogram_A, **common_args) #, name = name_list[0])\n",
    "plot_spectrogram(dt, t_corners_B, f_corners_B, flux_spectrogram_B, **common_args)# name = name_list[1])\n",
    "plot_spectrogram(dt, t_corners_merged, f_corners_merged, flux_spectrogram_merged, **common_args) #, name = 'spectrogram_merged')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tperiastron = pd.read_csv(\"KIC%s/%s/data/t_periastron.txt\" %(KIC, segment), header=0).values[0][0]\n",
    "t0_secondary = pd.read_csv(\"KIC%s/%s/data/t0_secondary.txt\" %(KIC, segment), header=0).values[0][0]\n",
    "\n",
    "def calculate_n_integer(t, t_ref, P):\n",
    "    min_n = round((min(t)-t_ref)/P)\n",
    "    max_n = round((max(t)-t_ref)/P)+1\n",
    "    n = np.arange(min_n, max_n, 1)\n",
    "    return n\n",
    "\n",
    "n_periastron = calculate_n_integer(time, tperiastron, lit_period)\n",
    "n_peclipses = calculate_n_integer(time, lit_t0, lit_period)\n",
    "n_seclipses = calculate_n_integer(time, t0_secondary, lit_period)\n",
    "\n",
    "periastron_passages = tperiastron + n_periastron*lit_period\n",
    "primary_passages = lit_t0+n_peclipses*lit_period\n",
    "secondary_passages = t0_secondary+n_seclipses*lit_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(16,6))\n",
    "ax.scatter(time, flux, c=\"lightsteelblue\", s=1)\n",
    "for i,(peri, prim, sec) in enumerate(zip(periastron_passages, primary_passages, secondary_passages)):\n",
    "    if i==0:\n",
    "        label1 = \"Periastron\"\n",
    "        label2 = \"Primary\"\n",
    "        label3 = \"Secondary\"\n",
    "    else:\n",
    "        label1, label2, label3 = None, None, None\n",
    "    ax.axvline(peri, lw=2, c=\"r\", label=label1)\n",
    "    ax.axvline(prim, lw=2, c=\"g\", label=label2)\n",
    "    ax.axvline(sec, lw=2, c=\"y\", label=label3)\n",
    "ax.legend(fontsize=20)    \n",
    "ax.set_xlabel(\"Time - %i [BKJD days]\"%kepler_tref, fontsize=20)\n",
    "ax.set_ylabel(\"Raw Flux (ppt)\", fontsize=20);\n",
    "ax.set_xlim(min(time), max(time)) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_eclipses_and_periastron(t, y, Tperiastron, Tprimary, Tsecondary, ax = ax):\n",
    "    #ax.scatter(t, y, s=1, c=\"lightsteelblue\")\n",
    "    \n",
    "    for i,(peri, prim, sec) in enumerate(zip(Tperiastron, Tprimary, Tsecondary)):\n",
    "        if i==0:\n",
    "            label1 = \"Periastron\"\n",
    "            label2 = \"Primary\"\n",
    "            label3 = \"Secondary\"\n",
    "        else:\n",
    "            label1, label2, label3 = None, None, None\n",
    "        \n",
    "        ax.axvline(peri, lw=2, c=\"r\", label=label1)\n",
    "        ax.axvline(prim, lw=2, c=\"g\", label=label2)\n",
    "        ax.axvline(sec, lw=2, c=\"y\", label=label3)\n",
    "    \n",
    "    ax.legend(fontsize=15)    \n",
    "    ax.set_ylabel(\"Raw Flux (ppt)\", fontsize=20);\n",
    "    ax.set_xlabel(\"Time - %i [BKJD days]\"%kepler_tref, fontsize=20)\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavelet Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "* <a href=\"https://www.kaggle.com/asauve/a-gentle-introduction-to-wavelet-for-data-analysis\"> [Kaggle]</a>, https://www.kaggle.com/mistag/extracting-bird-song-signatures-with-wavelets\n",
    "* <a href=\"https://www.mathworks.com/help/signal/ug/scalogram-computation-in-signal-analyzer.html\"> [Source of Text below]</a>\n",
    "* <a href=\"https://es.mathworks.com/help/wavelet/gs/continuous-wavelet-transform-and-scale-based-analysis.html\"> [Mathworks]\n",
    "\n",
    "The *spectrogram* is obtained by windowing the input signal with a WINDOW of constant length (duration) that is shifted in time and frequency. The window used in the spectrogram is even, real-valued, and does not oscillate. Because the spectrogram uses a constant window, the time-frequency resolution of the spectrogram is fixed.\n",
    "\n",
    "By contrast, the *CWT* is obtained by windowing the signal with a WAVELET that is scaled and shifted in time. The wavelet oscillates and can be complex-valued. The scaling and shifting operations are applied to a prototype wavelet. The scaling used in the CWT both shrinks and stretches the prototype wavelet. Shrinking the prototype wavelet yields short duration, high-frequency wavelets that are good at detecting transient events. Stretching the prototype wavelet yields long duration, low-frequency wavelets which are good at isolating long-duration, low frequency events.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "import scaleogram as scg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the mean value is mandatory, otherwise the borders of the data are considered as steps which create a lot of spurious cone shaped detection. https://www.kaggle.com/asauve/a-gentle-introduction-to-wavelet-for-data-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(d):\n",
    "    #NORMALIZE FUNCTION by - mean/sqrt(variance)\n",
    "    mean = np.mean(d)\n",
    "    variance = np.var(d)\n",
    "    d = (d - mean) / (np.sqrt(variance))\n",
    "    print(\"mean = \", mean)\n",
    "    print(\"std = \", np.sqrt(variance))\n",
    "    print(\"Mean Absolute Deviation = %0.02f\" % madev(d))\n",
    "    return d\n",
    "\n",
    "def madev(d, axis=None):\n",
    "    \"\"\" Mean absolute deviation of a signal \"\"\"\n",
    "    return np.mean(np.absolute(d - np.mean(d, axis)), axis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_norm = normalize(flux)\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.scatter(time, flux_norm, s=1, c=\"navy\")\n",
    "ax.set_title(\"Flux Normalized by mean/sqrt(variance)\", y=1.02, fontsize=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaleogram Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_wavelet = 'cmor2-6' #choice of 6th order morlet with B=2 taken after looking at various morlet wavelets and evaluating tradeoff (post discussion with Daniel del Ser and Octavi)\n",
    "scg.set_default_wavelet(chosen_wavelet)\n",
    "fig, ax = plt.subplots(1,2, figsize=(16,6))\n",
    "scg.plot_wav(chosen_wavelet, axes=ax, real=True, imag=True, yscale=\"linear\")\n",
    "central_frequency = pywt.central_frequency(chosen_wavelet)\n",
    "ax[0].set_ylim(-0.6, 0.6);\n",
    "print(central_frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some notes related to the code in the cell above:\n",
    "\n",
    "* Scales: With logscale on Y axis, the bandwith will have the same height at all scales which may be helpful for data interpretation. From https://paos.colorado.edu/research/wavelets/faq.html : \"The scale refers to the width of the wavelet. As the scale increases and the wavelet gets wider, it includes more of the time series, and the finer details get smeared out. The scale can be defined as the distance between oscillations in the wavelet (e.g. for the Morlet), or it can be some average width of the entire wavelet (e.g. for the Marr or Mexican hat). The period (or inverse frequency) is the approximate Fourier period that corresponds to the oscillations within the wavelet. For all wavelets, there is a one-to-one relationship between the scale and period. The relationship can be derived by finding the wavelet transform of a pure cosine wave with a known Fourier period, and then computing the scale at which the wavelet power spectrum reaches its maximum. For some wavelets the period has more meaning than others. For the Morlet, which has several smooth oscillations, the period is a well-defined quantity which measures the approximate Fourier period of the signal. For the Daubechies, which has irregularly-spaced oscillations, the period has less meaning and should probably be ignored.\"\n",
    "\n",
    "* Wavelet Choice: We choose the Morlet wavelet because: (1) it is commonly used, (2) it's simple, (3) it looks like a wave <a href=\"https://paos.colorado.edu/research/wavelets/wavelet3.html\">[ref]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_period_int = 0.1\n",
    "max_period_int = 700\n",
    "periods_wavelet = dt*np.logspace(np.log10(min_period_int), np.log10(max_period_int + 1), 1500)  \n",
    "scales  = scg.periods2scales(\n",
    "                            periods_wavelet,\n",
    "                            wavelet = chosen_wavelet,\n",
    "                            dt      = dt) #sampling interval\n",
    "\n",
    "#print(central_frequency*periods_wavelet/(scales*dt))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "d_t = np.mean(np.diff(time)) \n",
    "#periods_wavelet = np.logspace(np.log10(1/minfr), np.log10(f_nyquist), 500) #constant period bins in log space\n",
    "periods_wavelet = np.logspace(np.log10(1), np.log10(400), 200) #np.log10(1/minfr), np.log10(f_nyquist), 500) #constant period bins in log space\n",
    "scales  = scg.periods2scales(periods_wavelet, dt=d_t)\n",
    "scg.set_default_wavelet(chosen_wavelet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cyclesday_to_hertz(c):\n",
    "    return c*1.157*10**(-5)\n",
    "\n",
    "def scale_to_fourierFrequency(s):\n",
    "    #This applies to Morlet Wavelet\n",
    "    #See table 1 https://cobblab.eas.gatech.edu/seminar/torrence&compo98.pdf\n",
    "    num = 4*np.pi*s\n",
    "    den = central_frequency + np.sqrt(2+central_frequency**2)\n",
    "    f = num/den\n",
    "    return f\n",
    "\n",
    "print(\"Min. Frequency = %0.02f [c/d]\" %(minfr))\n",
    "print(\"\\t If %0.02f [c/d] is chosen as min. scale, the corresponding Fourier frequency is f=%0.02f [c/d]\" %(minfr, scale_to_fourierFrequency(minfr)))\n",
    "\n",
    "print(\"Max Frequency = %0.02f [c/d] (f_nyquist)\" %(f_nyquist))\n",
    "print(\"\\t If %0.02f [c/d] is chosen as max. scale, the corresponding Fourier frequency is f=%0.02f [c/d]\" %(f_nyquist, scale_to_fourierFrequency(f_nyquist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original code: https://github.com/chris-torrence/wavelets/blob/master/wave_python/waveletAnalysis.py\n",
    "       \n",
    "def calculate_scaleogram(t, f, scale_ary, \n",
    "                         y_axis           = \"frequency\", \n",
    "                         wavelet_type     = chosen_wavelet, \n",
    "                         y_scale          = \"log\", \n",
    "                         c_map            = \"plasma\",  #jet\n",
    "                         spectrum_type    = \"amp\",\n",
    "                         ax               = None,\n",
    "                         c_lim            = None,\n",
    "                         y_lim            = [minfr, f_max],\n",
    "                         x_label          = \"Time/Spatial Domain\",\n",
    "                         y_label          = None,\n",
    "                         fig_title        = \"Continuous Wavelet Transform Amplitude Spectrum\",\n",
    "                         name             = None):\n",
    "    \n",
    "    print(\"Computing the CWT with a %s mother wavelet...\" %wavelet_type)\n",
    "    \n",
    "    ax = scg.cws(t, \n",
    "             signal  = f,\n",
    "             scales  = scale_ary,\n",
    "             yaxis   = y_axis,\n",
    "             wavelet = wavelet_type, \n",
    "             yscale  = y_scale, #To be able to see the small periods and the large ones at once, it is better to use logarithmic scale on the Y axis. This is achieved with the yscale='log'option.\n",
    "             ax      = ax, \n",
    "             cmap    = c_map,\n",
    "             spectrum = spectrum_type,\n",
    "             clim    = c_lim\n",
    "    ) \n",
    "    \n",
    "    if y_label: ax.set_ylabel(y_label, fontsize=25)\n",
    "    \n",
    "    ax.set_title(fig_title, fontsize=28, y=1.02)\n",
    "    \n",
    "    if y_axis==\"frequency\":\n",
    "        ax.set_yticks([2, 3, 4, 6, 8, 10, 20, 30, 40, 50, 60]) #yaxis ticks in scaleograms\n",
    "        ax.set_ylim(y_lim)\n",
    "    ax.get_yaxis().set_major_formatter(ScalarFormatter())\n",
    "    ax.set_xlabel(x_label, fontsize=25)\n",
    "    \n",
    "    if name:\n",
    "        plt.tight_layout()\n",
    "        fig.savefig(\"KIC%s/%s/tfreq_analysis/%s.png\" %(KIC, segment,name), dpi=300)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the CWT \n",
    "\n",
    "* Cone of Influence: Represents the locations where the data is strongly affected by border effects due to the extent in time of the child wavelet. As a rule of thumb, you can use the COI as a visual marker to appreciate the precision in time at a given scale. <a href=\"https://github.com/alsauve/scaleogram/blob/master/doc/scale-to-frequency.ipynb\"> [Ref] </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(16,8))\n",
    "ax_spg = calculate_scaleogram(\n",
    "    time, \n",
    "    flux_norm, \n",
    "    scales, \n",
    "    ax            = ax,\n",
    "    wavelet_type  = chosen_wavelet,\n",
    "    c_lim         = (0,8), \n",
    "    c_map         = \"jet\",\n",
    "    x_label       = \"Time [d]\", \n",
    "    y_label       = r\"Frequency $d^{-1}$\",\n",
    "    #name          = \"full_cwt\"\n",
    ")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"KIC%s/frequency_analysis/full_cwt.png\" %KIC, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(16,8))\n",
    "fig.subplots_adjust(left=0,right=1,bottom=0,top=1)\n",
    "#scales = scg.periods2scales(np.logspace(np.log10(100), np.log10(f_nyquist), 500))\n",
    "ax_spg = calculate_scaleogram(\n",
    "    time, flux_norm, scales, \n",
    "    ax           = ax, \n",
    "    y_lim        = [minfr, 6],\n",
    "    wavelet_type = chosen_wavelet,\n",
    "    c_lim        = (0,8), \n",
    "    c_map        = \"jet\",\n",
    "    x_label      = \"Time [d]\", \n",
    "    y_label      = r\"Frequency $d^{-1}$\",\n",
    ")\n",
    "ax.set_ylim([minfr, 6])\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"KIC%s/frequency_analysis/zoom_cwt_lowfreqs.png\" %KIC, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(16,8))\n",
    "#scales = scg.periods2scales(np.logspace(np.log10(1/minfr), np.log10(100), 800))\n",
    "ax_spg = calculate_scaleogram(\n",
    "    time, \n",
    "    flux_norm, \n",
    "    scales, \n",
    "    ax           = ax, \n",
    "    y_lim        = [35, f_max],\n",
    "    wavelet_type = chosen_wavelet,\n",
    "    c_lim        = (0,8), \n",
    "    c_map        = \"jet\",\n",
    "    x_label      = \"Time [d]\", \n",
    "    y_label      = r\"Frequency $d^{-1}$\",\n",
    ")\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"KIC%s/frequency_analysis/zoom_cwt_highfreqs.png\" %KIC, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,1, figsize=(14,10))\n",
    "ax[0].scatter(time, flux_norm, s=2, c=\"navy\")\n",
    "ax_spg = calculate_scaleogram(\n",
    "    time, \n",
    "    flux_norm, \n",
    "    scales, \n",
    "    ax           = ax[1], \n",
    "    y_lim        = [f_min, f_max],\n",
    "    wavelet_type = chosen_wavelet,\n",
    "    c_lim        = (0,8), \n",
    "    c_map        = \"jet\",\n",
    "    x_label      = \"Time [d]\", \n",
    "    y_label      = r\"Frequency $d^{-1}$\",\n",
    ")\n",
    "ax[0].set_xlim([305, 310])\n",
    "ax[1].set_xlim([305, 310])\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"KIC%s/frequency_analysis/perhaps_data_gap.png\" %KIC, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the Retrieved Oscillations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osc_data = osc_data.sort_values(by=['freq'], ascending=True).reset_index(drop=True)\n",
    "osc_data.to_csv(\"KIC%s/frequency_analysis/retrieved_osc.csv\" %KIC, sep=\",\", header=True, columns=osc_data.columns, index=False)\n",
    "\n",
    "mask = osc_data.d_to_int<0.01\n",
    "teo = osc_data[mask]\n",
    "teo.sort_values(by=['freq'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(16,8))\n",
    "ax_spg = calculate_scaleogram(\n",
    "    time, flux_norm, scales, \n",
    "    ax           = ax, \n",
    "    y_axis       = \"frequency\",\n",
    "    #y_lim        = [minfr, 6],\n",
    "    wavelet_type = chosen_wavelet,\n",
    "    c_lim        = (0,10), \n",
    "    c_map        = \"jet\",\n",
    "    x_label      = \"Time [d]\", \n",
    "    y_label      = r\"Frequency [$d^{-1}$]\",\n",
    ")\n",
    "for t in teo.freq.values:\n",
    "    print(t)\n",
    "    ax.axhline(t, color=\"white\", lw=3, ls=\"-\", alpha=0.6)\n",
    "    \n",
    "fig.tight_layout()\n",
    "fig.savefig(\"KIC%s/frequency_analysis/full_cwt_retrieved_oscillations.png\" %KIC, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests with Wavelet Transforms\n",
    "\n",
    "### Do a CWT on Phase-Folded Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold_data(ary, ntimes, P_ref, t0_ref):\n",
    "    nperiod = ntimes*P_ref\n",
    "    ary_fold = ((ary - t0_ref + 0.5 * nperiod) % nperiod)/nperiod - 0.5\n",
    "    return ary_fold \n",
    "\n",
    "#Phase-fold times\n",
    "#periastron_passages_fold = fold_data(periastron_passages, 1, lit_period, lit_t0)\n",
    "#primary_passages_fold = fold_data(primary_passages, 1, lit_period, lit_t0)\n",
    "#secondary_passages_fold = fold_data(secondary_passages, 1, lit_period, t0_secondary)\n",
    "x_fold = fold_data(x, 1, lit_period, lit_t0)\n",
    "time_fold = fold_data(time, 1, lit_period, lit_t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(16, 7))\n",
    "ax.scatter(x_fold, y, s=1, label=\"Folded Raw Light Curve\")\n",
    "ax.scatter(time_fold, flux_norm, s=1, label = \"Folded Osc. Model + Noise. Model\")\n",
    "ax.set_xlim([-0.5, 0.5])\n",
    "ax.set_ylim([-40, 20])\n",
    "ax.set_xlabel(\"Orbital Phase\", size=30)\n",
    "ax.set_ylabel('Raw Flux [ppt]', size=30)\n",
    "ax.legend(fontsize=18, markerscale=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(16,8))\n",
    "calculate_scaleogram(time_fold, \n",
    "                     flux_norm, \n",
    "                     scales, \n",
    "                     wavelet_type   = chosen_wavelet,\n",
    "                     ax             = ax, \n",
    "                     c_lim          = (0,10),\n",
    "                     x_label        = \"Phase [d]\", \n",
    "                     y_label        = r\"Frequency $d^{-1}$\",\n",
    "                     y_ticks        = kic_ticks,\n",
    "                     \n",
    "                    )\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"phasefolded_cwt.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise with Injected Low SNR signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_model = read_txt(\"KIC%s/%s/tfreq_analysis/noise_model.txt\" %(KIC, segment), header=1, names=[\"Time\", \"Flux\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_noise = ls_estimator(noise_model.Time, noise_model.Flux, freq_grid, normalization=\"psd\")\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(15,6))\n",
    "ax.plot(ls_spec[\"periodogram\"][0], ls_spec[\"periodogram\"][1], alpha=0.5, label=\"Raw LC\")\n",
    "ax.plot(ls_noise[\"periodogram\"][0], ls_noise[\"periodogram\"][1], label=\"Best-fit Noise Model\")\n",
    "ax.set_xlabel(r\"Frequency [$d^{-1}$]\", size=20)\n",
    "ax.set_ylabel(\"Power\")\n",
    "ax.set_title(\"LS Periodogram\")\n",
    "ax.legend(fontsize=15)\n",
    "ax.set_xlim(0,f_max);\n",
    "ax.text(0.1,0.6, \"Low Frequency g-mode regime\", fontsize=15, transform=ax.transAxes, bbox=dict(facecolor='red', alpha=0.4));\n",
    "ax.text(0.62,0.6, \"High Frequency p-mode regime\", fontsize=15, transform=ax.transAxes, bbox=dict(facecolor='green', alpha=0.4));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noisify(sig, noise_amp=1):\n",
    "    return sig + (np.random.random(len(sig))-0.5)*2*noise_amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_fake = np.linspace(min(noise_model.Time), max(noise_model.Time), len(noise_model.Time))\n",
    "amplitude_fake = 0.2\n",
    "freq_fake = 10.0\n",
    "theta = 0 # amplitude of our sine wave at time 0\n",
    "y_fake = amplitude_fake * np.sin(2 * np.pi * freq_fake * x_fake + theta)\n",
    "y_fake_noisy = noisify(y_fake, noise_amp=1)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(16,6))\n",
    "ax.scatter(x_fake, y_fake, s=1, c=\"dodgerblue\", label=\"Fake Signal\") #r\"f$_{fake}$=%0.1f [c/d], A=%0.02f [ppt]\" %(freq_fake, amplitude), c=\"salmon\")\n",
    "ax.scatter(x_fake, y_fake_noisy, s=0.5, alpha=0.5, c=\"green\", label=\"Fake Signal with White Noise\") \n",
    "ax.scatter(x_fake, noise_model.Flux+y_fake_noisy, s=1, color=\"orange\", alpha=0.5, label=\"Original signal + Fake signal with White Noise\")#  label=r\"f$_{fake}$=%0.1f [c/d], A=%0.02f [ppt]\" %(freq_fake, amplitude), c=\"salmon\")\n",
    "ax.plot(noise_model.Time, noise_model.Flux, \"k.\", ms=0.5, label=\"Noise Best-fit model\")\n",
    "\n",
    "ax.legend(fontsize=15, markerscale=4)\n",
    "ax.set_title(\"Best-fit Noise Model + Injected Signal\", y=1.02, fontsize=25)\n",
    "ax.set_xlabel(\"Time [d]\", fontsize=20);\n",
    "ax.set_ylabel(\"Raw flux [ppt]\", fontsize=20);\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(16,6))\n",
    "calculate_scaleogram(x_fake, \n",
    "                     noise_model.Flux+y_fake_noisy, \n",
    "                     scales, \n",
    "                     wavelet_type  = chosen_wavelet, \n",
    "                     x_label       = \"Time [d]\", \n",
    "                     y_label       = r\"Frequency $d^{-1}$\",\n",
    "                     ax = ax, c_lim=(0,8))\n",
    "#fig.savefig(\"scg_noise_f%ia%0.01f.png\" %(freq_fake,  amplitude_fake), dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Noise displays usually as a patchwork of features and some bumps can look like real data features, so you have to be careful when using real data to check the level of noise when appropriate. I recommend this fairly complete paper on the significance level by Z. Ge. if you have some time. (https://www.kaggle.com/asauve/a-gentle-introduction-to-wavelet-for-data-analysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_fake = np.linspace(min(noise_model.Time), max(noise_model.Time), len(noise_model.Time))\n",
    "amplitude_fake = [0.2, 0.5]\n",
    "freq_fake = [4.0, 30]\n",
    "theta = [0, 0] # amplitude of our sine wave at time 0\n",
    "\n",
    "allwaves, y_fake, y_fake_noisy = [], [], []\n",
    "damping_coefficent = 0.1 \n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(16,8))\n",
    "\n",
    "for i in range(0,len(amplitude_fake)):\n",
    "    y_fake = amplitude_fake[i] * np.sin(2 * np.pi * freq_fake[i] * x_fake + theta[i])\n",
    "    y_fake_noisy = noisify(y_fake, noise_amp=1)\n",
    "    allwaves.append(y_fake_noisy)\n",
    "\n",
    "multiple_waves = np.copy(noise_model.Flux)\n",
    "for w in allwaves: multiple_waves+=w\n",
    "    \n",
    "scales = scg.periods2scales(np.logspace(np.log10(0.1), np.log10(f_nyquist), 600))\n",
    "calculate_scaleogram(x_fake, \n",
    "                     multiple_waves, \n",
    "                     scales, \n",
    "                     wavelet_type  = chosen_wavelet, \n",
    "                     ax            = ax, \n",
    "                     c_lim         = (0,10),\n",
    "                     y_lim         = (f_min, f_max),\n",
    "                     y_ticks       = kic_ticks, \n",
    "                     x_label       = \"Time [d]\", \n",
    "                     y_label       = r\"Frequency $d^{-1}$\")\n",
    "\n",
    "#fig.savefig(\"scg_noise_allwaves.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_wavelets = {\"cmor1-1\":    \"B=1.0, CF=1.0\",\n",
    "                 \"cmor1_3\":    \"B=1.0, CF=3.0\" ,\n",
    "                 \"cmor1-5\":    \"B=1.0, CF=5.0\",\n",
    "                 \"cmor1-6\":    \"B=1.0, CF=6.0\",\n",
    "                 \"cmor2-6\":    \"B=2.0, CF=6.0\",\n",
    "                 \"cmor1-8\":    \"B=1.0, CF=8.0\"}\n",
    "\n",
    "nwavelets = len(test_wavelets.keys())\n",
    "fig, ax = plt.subplots(nwavelets,1, figsize=(15,35), sharex=True)\n",
    "fig.subplots_adjust(hspace=0.3)\n",
    "scales = scg.periods2scales(np.logspace(np.log10(1/minfr), np.log10(f_nyquist), 800))\n",
    "\n",
    "for i, (w, title) in enumerate(test_wavelets.items()):\n",
    "        calculate_scaleogram(\n",
    "        time, flux_norm, scales, \n",
    "        wavelet_type    = w, \n",
    "        x_label         = None, \n",
    "        y_label         = r\"Frequency [$d^{-1}$]\", \n",
    "        #y_lim           = [minfr, 10],\n",
    "        y_ticks         = kic_ticks, \n",
    "        fig_title       = title,\n",
    "        ax              = ax[i],\n",
    "        c_map           = \"jet\",\n",
    "        c_lim           = (0,8)\n",
    ") \n",
    "fig.tight_layout()\n",
    "fig.savefig(\"cmorlet_types.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = 0\n",
    "amplitude_fake = 0.5#[0.2, 0.3, 1, 0.8]\n",
    "freq_fake = 5\n",
    "damped_signal = (amplitude_fake*(1-0.8*np.sin(2*np.pi/50*freq_fake*x_fake + theta)))* np.sin(2*np.pi *freq_fake* x_fake + theta)\n",
    "damped_signal_noisy = noisify(damped_signal, noise_amp=0.1)\n",
    "\n",
    "fig, ax = plt.subplots(2,1, figsize=(16,13))\n",
    "fig.subplots_adjust(hspace=0.25)\n",
    "#ax[0].scatter(noise_model.Time, noise_model.Flux, label=\"Noise model from Fit\", s=1)\n",
    "ax[0].scatter(x_fake, damped_signal_noisy, label=\"Fake Signal with Noise\", s=1)\n",
    "ax[0].legend(fontsize=18, markerscale=3)\n",
    "ax[0].set_xlabel(\"Time [d]\"); \n",
    "ax[0].set_ylabel(\"Raw Flux [ppt]\")\n",
    "\n",
    "'''\n",
    "###### Best-fit noise model and noisy signal\n",
    "calculate_scaleogram(noise_model.Time.values, noise_model.Flux+damped_signal_noisy, \n",
    "                     scales, \n",
    "                     wavelet_type=\"cmor1.5-6.0\", \n",
    "                     c_lim         = (0, 10),\n",
    "                     y_lim         = (f_min, f_max), \n",
    "                     ax            = ax[1], \n",
    "                     x_label       = \"Time [d]\", \n",
    "                     y_label       = r\"Frequency $d^{-1}$\",\n",
    "                     fig_title     = None)\n",
    "\n",
    "#fig.savefig(\"modulating_amplitude_noNoise.png\")\n",
    "fig.savefig(\"modulating_amplitude_Noise.png\")\n",
    "'''\n",
    "\n",
    "###### Pure Noisy Signal\n",
    "calculate_scaleogram(noise_model.Time.values, \n",
    "                     damped_signal_noisy, \n",
    "                     scales, \n",
    "                     wavelet_type  = chosen_wavelet, \n",
    "                     c_lim         = (0, 10),\n",
    "                     y_lim         = (f_min, f_max), \n",
    "                     ax            = ax[1], \n",
    "                     x_label       = \"Time [d]\", \n",
    "                     y_label       = r\"Frequency $d^{-1}$\",\n",
    "                     fig_title     = None)\n",
    "fig.savefig(\"puresignal_cwt.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# import pycwt \n",
    "from waveletFunctions import wavelet, wave_signif\n",
    "\n",
    "s0 = 2 * dt  # Starting scale\n",
    "dj = 0.125   # Twelve sub-octaves per octaves\n",
    "J = round((dj**-1)*np.log2((Nt*dt)/s0))   # Seven powers of two with dj sub-octaves #(1./dj)*np.log2((Nt*dt)/s0)\n",
    "print(\"J = \", J)\n",
    "pad = 1  # pad the time series with zeroes (recommended)\n",
    "mother = pycwt.Morlet(6)\n",
    "lag1, _, _ = pycwt.ar1(flux_norm)  # Lag-1 autocorrelation coefficient for red noise background\n",
    "print(\"lag-1 autocorrelation for red noise background = \", lag1)\n",
    "\n",
    "wave, periods_cwt, scales, coi = wavelet(flux_norm, dt, pad, dj, s0, J, 'MORLET')\n",
    "freqs_cwt = 1/periods_cwt\n",
    "power_cwt = (np.abs(wave)) ** 2  # compute wavelet power spectrum\n",
    "global_ws = (np.sum(power_cwt, axis=1) / Nt)  # time-average over all times\n",
    "\n",
    "print(\"Orbital Frequency = %0.04f [c/d]\" % orbital_frequency)\n",
    "print(\"Min scale = %0.04f --> %0.04f [d]\" % (min(scales), 1/scale_to_fourierFrequency(min(scales))))\n",
    "print(\"Max scale = %0.04f --> %0.04f [d] \" % (max(scales), 1/scale_to_fourierFrequency(max(scales))))\n",
    "\n",
    "\n",
    "# Significance levels:\n",
    "signif = wave_signif(([variance]), dt=dt, sigtest=0, scale=scales, lag1=lag1, mother='MORLET')\n",
    "sig95 = signif[:, np.newaxis].dot(np.ones(Nt)[np.newaxis, :])  # expand signif --> (J+1)x(N) array\n",
    "sig95 = power_cwt / sig95  # where ratio > 1, power is significant\n",
    "\n",
    "# Global wavelet spectrum & significance levels:\n",
    "dof = Nt - scales  # the -scale corrects for padding at edges\n",
    "global_signif = wave_signif(variance, dt=dt, scale=scales, sigtest=1, lag1=lag1, dof=dof, mother='MORLET')\n",
    "\n",
    "# Scale-average between El Nino periods of 2--8 years\n",
    "scale_min = orbital_frequency\n",
    "scale_max = max(osc_data.freq)\n",
    "avg = np.logical_and(scales >= scale_min, scales < scale_max)\n",
    "Cdelta = 0.776  # this is for the MORLET wavelet\n",
    "scale_avg = scales[:, np.newaxis].dot(np.ones(Nt)[np.newaxis, :])  # expand scale --> (J+1)x(N) array\n",
    "scale_avg = power_cwt / scale_avg  # [Eqn(24)]\n",
    "scale_avg = dj * dt / Cdelta * sum(scale_avg[avg, :])  # [Eqn(24)]\n",
    "scaleavg_signif = wave_signif(variance, dt=dt, scale=scales, sigtest=2, lag1=lag1, dof=([scale_min, scale_max]), mother='MORLET')\n",
    "\n",
    "\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.ticker as ticker\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "xlim = ([min(time), max(time)])  # plotting range\n",
    "\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "gs = GridSpec(2, 4, hspace=0.4, wspace=0.75)\n",
    "plt.subplots_adjust(left=0.1, bottom=0.05, right=0.8, top=0.95, wspace=0, hspace=0)\n",
    "\n",
    "#--- Contour plot wavelet power spectrum\n",
    "# plt3 = plt.subplot(3, 1, 2)\n",
    "plt3 = plt.subplot(gs[0, 0:3])\n",
    "levels = [0, 0.5, 1, 2, 4, 999]\n",
    "CS = plt.contourf(time, freqs_cwt, power_cwt, len(levels))  #*** or use 'contour'\n",
    "im = plt.contourf(CS, levels=levels, colors=['white','bisque','orange','orangered','crimson'])\n",
    "plt.contour(time, freqs_cwt, sig95, [-99, 1], colors='k', linewidths=1) # significance contour, levels at -99 (fake) and 1 (95# signif)\n",
    "plt.plot(time, coi[1:], 'k') # cone-of-influence, anything \"below\" is dubious\n",
    "\n",
    "# format y-scale\n",
    "plt3.set_yscale('log', basey=2, subsy=None)\n",
    "plt.ylim([minfr, f_max])\n",
    "#ax = plt.gca().yaxis\n",
    "#ax.set_major_formatter(ticker.ScalarFormatter())#\n",
    "#3plt3.ticklabel_format(axis='y', style='plain')\n",
    "#plt3.invert_yaxis()\n",
    "# set up the size and location of the colorbar\n",
    "#position=fig.add_axes([0.5,0.36,0.2,0.01]) \n",
    "#plt.colorbar(im, cax=position, orientation='vertical') #, fraction=0.05, pad=0.5, \n",
    "\n",
    "#--- Plot global wavelet spectrum\n",
    "plt4 = plt.subplot(gs[0, -1])\n",
    "plt.plot(global_ws, freqs_cwt)\n",
    "plt.plot(global_signif, freqs_cwt, '--')\n",
    "plt.xlabel('Power (\\u00B0C$^2$)')\n",
    "plt.xlim([0, 1.25 * np.max(global_ws)])\n",
    "# format y-scale\n",
    "plt4.set_yscale('log', basey=2, subsy=None)\n",
    "plt.ylim([minfr, f_max])\n",
    "#ax = plt.gca().yaxis\n",
    "#ax.set_major_formatter(ticker.ScalarFormatter())\n",
    "#plt4.ticklabel_format(axis='y', style='plain')\n",
    "#plt4.invert_yaxis()\n",
    "\n",
    "plt5 = plt.subplot(gs[1, 0:3])\n",
    "plt.plot(time, scale_avg, 'k')\n",
    "plt.plot(xlim, scaleavg_signif + [0, 0], '--')\n",
    "show_eclipses_and_periastron(time, flux_norm, periastron_passages, primary_passages, secondary_passages, ax=plt5)\n",
    "plt.xlim(xlim[:])\n",
    "plt.xlabel('Time (d)')\n",
    "plt.ylabel('Avg variance (ppt$^2$)')\n",
    "plt.title('Scale-average Time Series')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "192.333px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "881.646px",
    "left": "1550px",
    "right": "20px",
    "top": "119px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
